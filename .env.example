# =============================================================================
# Configuration API pour le LLM et les Embeddings
# =============================================================================
# Choisissez l'une des configurations ci-dessous selon votre fournisseur d'API

# -----------------------------------------------------------------------------
# Option 1 : Azure OpenAI (Recommandé pour la production)
# -----------------------------------------------------------------------------
API_KEY=your_azure_api_key_here
API_BASE_URL=https://your-resource.openai.azure.com/openai/v1/
LLM_MODEL_NAME=your-llm-model
EMBEDDING_MODEL_NAME=your-embedding-model

# -----------------------------------------------------------------------------
# Option 2 : Groq (Rapide et gratuit pour le développement)
# -----------------------------------------------------------------------------
# API_KEY=gsk_your_groq_api_key_here
# API_BASE_URL=https://api.groq.com/openai/v1
# LLM_MODEL_NAME=llama-3.1-70b-versatile
# EMBEDDING_MODEL_NAME=bge-m3

# -----------------------------------------------------------------------------
# Option 3 : Grok (X.AI)
# -----------------------------------------------------------------------------
# API_KEY=xai-your_grok_api_key_here
# API_BASE_URL=https://api.x.ai/v1/
# LLM_MODEL_NAME=grok-beta
# EMBEDDING_MODEL_NAME=bge-m3

# =============================================================================
# NOTES:
# - Décommentez seulement la configuration que vous souhaitez utiliser
# - Pour Azure OpenAI, remplacez "your-resource" par le nom de votre ressource
# =============================================================================
