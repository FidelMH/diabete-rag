"""
Test et √©valuation du syst√®me RAG avec RAGAS.

Ce script permet d'√©valuer la qualit√© du syst√®me RAG en utilisant :
- G√©n√©ration automatique d'un dataset de test
- M√©triques RAGAS (Faithfulness, Answer Relevancy, Context Precision/Recall)
- LLM externe (Groq/OpenAI) pour une √©valuation de qualit√©
"""

import os
from dotenv import load_dotenv
from documents import EmbedderRag
from text_cleaner import TextCleaner

from llama_index.core import SimpleDirectoryReader, Settings
from llama_index.llms.openai_like import OpenAILike
from llama_index.embeddings.ollama import OllamaEmbedding
from llama_index.llms.ollama import Ollama
from llama_index.core.node_parser import SentenceSplitter
from ragas.testset import TestsetGenerator
from ragas.integrations.llama_index import evaluate
# from ragas.llms import LangchainLLMWrapper
from ragas import embeddings
from ragas.llms import LlamaIndexLLMWrapper
from ragas.embeddings import LangchainEmbeddingsWrapper
from langchain_ollama import OllamaEmbeddings as LangchainOllamaEmbeddings
from ragas.metrics import (
    Faithfulness,
    AnswerRelevancy,
    ContextPrecision,
    ContextRecall,
)

# Charger les variables d'environnement
load_dotenv()
API_KEY = os.getenv("API_KEY")
API_BASE_URL = os.getenv("API_BASE_URL") 
EMBEDDING_MODEL_NAME = os.getenv("EMBEDDING_MODEL_NAME")
LLM_MODEL_NAME = os.getenv("LLM_MODEL_NAME")

if not API_KEY:
    raise ValueError("La cl√© API_KEY n'est pas d√©finie dans le fichier .env")
if not API_BASE_URL:
    raise ValueError("API_BASE_URL non trouv√©e dans le fichier .env")
if not EMBEDDING_MODEL_NAME:
    raise ValueError("EMBEDDING_MODEL_NAME n'est pas d√©finie dans le fichier .env")
if not LLM_MODEL_NAME:
    raise ValueError("LLM_MODEL_NAME n'est pas d√©finie dans le fichier .env")


class RAGEvaluator:
    """
    Classe pour √©valuer un syst√®me RAG avec RAGAS.
    """

    def __init__(
        self,
        documents_path: str = "./documents",
        model_name: str = LLM_MODEL_NAME ,
        embed_model_name: str = EMBEDDING_MODEL_NAME,
        testset_size: int = 5
    ):
        """
        Initialise l'√©valuateur RAG.

        Args:
            documents_path: Chemin vers les documents
            model_name: Mod√®le Groq pour l'√©valuation
            embed_model_name: Mod√®le d'embedding Ollama
            testset_size: Nombre de questions de test √† g√©n√©rer
        """
        self.documents_path = documents_path
        self.model_name = model_name
        self.embed_model_name = embed_model_name
        self.testset_size = testset_size

        # Initialiser le LLM Groq pour l'√©valuation (LangChain)
        self.llm = OpenAILike(
            model=self.model_name,
            api_key=API_KEY,
            api_base=API_BASE_URL,
            temperature=0.3,
            is_chat_model=True
        )
        Settings.llm = self.llm
        # self.llm = Ollama(
        #     model=self.model_name,
        #     temperature=0.3,
        #     is_chat_model=True
        # )

        # Initialiser le mod√®le d'embedding local (LangChain)
        self.embed_model = OllamaEmbedding(
            model_name=self.embed_model_name,
        )

        print(f"‚úì LLM initialis√©: {self.model_name}")
        print(f"‚úì Embedding initialis√©: {self.embed_model_name}")

    def generate_testset(self):
        """
        G√©n√®re un dataset de test √† partir des documents.

        Returns:
            Dataset de test RAGAS
        """
        print(f"\nüìö Chargement des documents depuis '{self.documents_path}'...")
        documents = SimpleDirectoryReader(self.documents_path).load_data()
        print(f"‚úì {len(documents)} document(s) charg√©(s)")

        # Nettoyer les documents pour am√©liorer la qualit√© du testset
        print("\nüßπ Nettoyage des documents...")
        documents = TextCleaner.clean_documents(
            documents,
            remove_urls=True,
            normalize_medical=False
        )
        print("‚úì Documents nettoy√©s (m√©tadonn√©es headlines ajout√©es)")

        print(f"\nüîß Initialisation du g√©n√©rateur de testset...")
        # # Wrapper les mod√®les LangChain pour RAGAS
        # generator_llm = LangchainLLMWrapper(self.llm)
        # generator_embeddings = LangchainEmbeddingsWrapper(self.embed_model)

        generator = TestsetGenerator.from_llama_index(
            llm=self.llm,
            embedding_model=self.embed_model,
        )

        print(f"\n‚öôÔ∏è  G√©n√©ration de {self.testset_size} questions de test...")
        print("   (Cette op√©ration peut prendre quelques minutes)")

        testset = generator.generate_with_llamaindex_docs(
            documents,
            testset_size=self.testset_size,
        )

        print(f"‚úì Testset g√©n√©r√© avec succ√®s!")
        return testset

    def evaluate_rag(self, testset):
        """
        √âvalue le syst√®me RAG avec les m√©triques RAGAS.

        Args:
            testset: Dataset de test g√©n√©r√©

        Returns:
            R√©sultats de l'√©valuation
        """
        print(f"\nüèóÔ∏è  Construction de l'index vectoriel...")
        embedder = EmbedderRag(
            model_name=self.embed_model_name,
            input_path=self.documents_path
        )
        index = embedder.build_or_load_index()

        print(f"\nüîç Cr√©ation du QueryEngine...")
        query_engine = index.as_query_engine(llm=self.llm)

        print(f"\nüìä Configuration des m√©triques d'√©valuation...")
        evaluator_llm = LlamaIndexLLMWrapper(self.llm)

        # Configuration du mod√®le d'embedding pour RAGAS
        # RAGAS utilise Langchain pour les embeddings, nous devons donc wrapper notre mod√®le
        ragas_embeddings = LangchainEmbeddingsWrapper(
            LangchainOllamaEmbeddings(model=self.embed_model_name)
        )

        metrics = [
            Faithfulness(llm=evaluator_llm),
            AnswerRelevancy(llm=evaluator_llm, embeddings=ragas_embeddings),
            ContextPrecision(llm=evaluator_llm),
            ContextRecall(llm=evaluator_llm),
        ]

        print(f"\nüöÄ √âvaluation en cours...")
        print("   M√©triques:")
        print("   - Faithfulness: Fid√©lit√© de la r√©ponse aux documents")
        print("   - Answer Relevancy: Pertinence de la r√©ponse")
        print("   - Context Precision: Pr√©cision du contexte r√©cup√©r√©")
        print("   - Context Recall: Rappel du contexte pertinent")

        ragas_dataset = testset.to_evaluation_dataset()

        result = evaluate(
            query_engine=query_engine,
            metrics=metrics,
            dataset=ragas_dataset,
        )

        return result

    def display_results(self, result):
        """
        Affiche les r√©sultats de l'√©valuation.

        Args:
            result: R√©sultats de l'√©valuation RAGAS
        """
        print("\n" + "="*60)
        print("üìà R√âSULTATS DE L'√âVALUATION")
        print("="*60)

        df = result.to_pandas()

        # Afficher les scores globaux (moyenne de chaque m√©trique)
        if not df.empty:
            print("\nüéØ Scores moyens:")
            # Calculate the mean for numeric columns only
            for metric in df.select_dtypes(include='number').columns:
                mean_score = df[metric].mean(skipna=True)
                print(f"   {metric}: {mean_score:.4f}")

        print("\nüìã R√©sultats d√©taill√©s:")
        print(df.to_string())

        # Sauvegarder les r√©sultats
        output_file = "ragas_evaluation_results.csv"
        df.to_csv(output_file, index=False)
        print(f"\nüíæ R√©sultats sauvegard√©s dans '{output_file}'")

        return df


def main():
    """
    Fonction principale pour ex√©cuter l'√©valuation RAGAS.
    """
    print("="*60)
    print("üß™ √âVALUATION RAG AVEC RAGAS")
    print("="*60)

    # Initialiser l'√©valuateur
    evaluator = RAGEvaluator(
        documents_path="./documents",
        # model_name="openai/gpt-oss-20b",  # Mod√®le Groq
        # embed_model_name="bge-m3",  # Mod√®le d'embedding local
        testset_size=8  # Nombre de questions √† g√©n√©rer
    )

    # G√©n√©rer le testset
    testset = evaluator.generate_testset()

    # √âvaluer le syst√®me RAG
    result = evaluator.evaluate_rag(testset)

    # Afficher les r√©sultats
    df = evaluator.display_results(result)

    print("\n‚úÖ √âvaluation termin√©e avec succ√®s!")


if __name__ == "__main__":
    main()
